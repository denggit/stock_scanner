# ğŸš€ ä¸Šå‡é€šé“å›å½’æ¨¡å—ä½¿ç”¨ç¤ºä¾‹

## ğŸ“‹ ç›®å½•

- [ğŸ¯ åŸºæœ¬ä½¿ç”¨](#-åŸºæœ¬ä½¿ç”¨)
- [ğŸ“Š å†å²æ•°æ®åˆ†æ](#-å†å²æ•°æ®åˆ†æ)
- [âš™ï¸ å‚æ•°é…ç½®](#ï¸-å‚æ•°é…ç½®)
- [ğŸ” é«˜çº§åŠŸèƒ½](#-é«˜çº§åŠŸèƒ½)
- [ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–](#-æ€§èƒ½ä¼˜åŒ–)
- [ğŸ› æ•…éšœæ’é™¤](#-æ•…éšœæ’é™¤)

---

## ğŸ¯ åŸºæœ¬ä½¿ç”¨

### 1.1 å•ç‚¹é€šé“æ‹Ÿåˆ

```python
import pandas as pd
import numpy as np
from backend.business.factor.core.engine.library.channel_analysis.rising_channel import AscendingChannelRegression

# å‡†å¤‡æ•°æ®
df = pd.DataFrame({
    'trade_date': pd.date_range('2023-01-01', periods=200, freq='D'),
    'open': [10 + i * 0.01 + np.random.normal(0, 0.1) for i in range(200)],
    'high': [10 + i * 0.01 + np.random.normal(0, 0.2) for i in range(200)],
    'low': [10 + i * 0.01 - np.random.normal(0, 0.2) for i in range(200)],
    'close': [10 + i * 0.01 + np.random.normal(0, 0.1) for i in range(200)],
    'volume': [np.random.randint(1000000, 10000000) for _ in range(200)]
})

# åˆå§‹åŒ–åˆ†æå™¨
analyzer = AscendingChannelRegression()

# æ‹Ÿåˆé€šé“
state = analyzer.fit_channel(df)

# è·å–ç»“æœ
result = state.to_dict()
print(result)
```

**è¿”å›ç»“æœå­—æ®µè¯´æ˜ï¼š**

```python
{
    # å›å½’å‚æ•°
    "beta": 0.0216,           # æ–œç‡ Î²_t
    "sigma": 0.4717,          # æ ‡å‡†å·® Ïƒ_t
    "r2": 0.6832,             # å›å½’æ‹Ÿåˆä¼˜åº¦ RÂ²
    
    # é€šé“è¾¹ç•Œï¼ˆå½“å‰ï¼‰
    "mid_today": 14.7545,     # ä»Šæ—¥ä¸­è½´ä»·
    "upper_today": 15.6980,   # ä»Šæ—¥ä¸Šæ²¿ä»·
    "lower_today": 13.8111,   # ä»Šæ—¥ä¸‹æ²¿ä»·
    
    # é€šé“è¾¹ç•Œï¼ˆæ˜æ—¥é¢„æµ‹ï¼‰
    "mid_tomorrow": 14.7762,  # æ˜æ—¥é¢„æµ‹ä¸­è½´ä»·
    "upper_tomorrow": 15.7197, # æ˜æ—¥é¢„æµ‹ä¸Šæ²¿ä»·
    "lower_tomorrow": 13.8327, # æ˜æ—¥é¢„æµ‹ä¸‹æ²¿ä»·
    
    # é€šé“çŠ¶æ€
    "channel_status": "NORMAL", # é€šé“çŠ¶æ€ (NORMAL/BREAKOUT/BREAKDOWN)
    
    # é”šç‚¹ä¿¡æ¯
    "anchor_date": "2023-03-31T00:00:00",  # é”šç‚¹æ—¥æœŸ
    "anchor_price": 11.5916,               # é”šç‚¹ä»·æ ¼
    
    # çªç ´è®¡æ•°å™¨
    "break_cnt_up": 0,        # è¿ç»­çªç ´ä¸Šæ²¿æ¬¡æ•°
    "break_cnt_down": 0,      # è¿ç»­çªç ´ä¸‹æ²¿æ¬¡æ•°
    
    # é‡é”šå¤±è´¥è®¡æ•°å™¨
    "reanchor_fail_up": 0,    # é‡é”šå¤±è´¥ï¼ˆä¸Šæ²¿ï¼‰
    "reanchor_fail_down": 0,  # é‡é”šå¤±è´¥ï¼ˆä¸‹æ²¿ï¼‰
    
    # å…¶ä»–ä¿¡æ¯
    "cumulative_gain": 0.3445, # ç´¯è®¡æ¶¨å¹…
    "last_update": "2023-07-19T00:00:00", # æœ€åæ›´æ–°æ—¶é—´
    "window_size": 108,       # çª—å£å¤§å°
    "days_since_anchor": 107, # è·ç¦»é”šç‚¹å¤©æ•°
    
    # åˆ†æå­—æ®µ
    "width_pct": 0.1229,      # é€šé“å®½åº¦ç™¾åˆ†æ¯” (ä¸Šæ²¿-ä¸‹æ²¿)/ä¸­è½´ä»·
    "slope_deg": 1.4052,      # æ–œç‡è§’åº¦ï¼ˆåº¦ï¼‰
    "volatility": 0.0320      # æ³¢åŠ¨ç‡ Ïƒ/ä¸­è½´ä»·
}
```

### 1.2 ä½¿ç”¨æŠ€æœ¯æŒ‡æ ‡å·¥å…·

```python
from backend.utils.indicators import CalIndicators

# ä½¿ç”¨æŠ€æœ¯æŒ‡æ ‡å·¥å…·è®¡ç®—ä¸Šå‡é€šé“
channel_info = CalIndicators.ascending_channel(df, **params)

print(f"æ–œç‡: {channel_info['beta']:.4f}")
print(f"é€šé“çŠ¶æ€: {channel_info['channel_status']}")
print(f"æ‹Ÿåˆè´¨é‡: {channel_info['r2']:.3f}")
```

---

## ğŸ“Š å†å²æ•°æ®åˆ†æ

### 2.1 å†å²é€šé“æ‹Ÿåˆ

```python
# è®¡ç®—å†å²é€šé“æ•°æ®
history_df = analyzer.fit_channel_history(df, min_window_size=60)

print(f"å†å²æ•°æ®å½¢çŠ¶: {history_df.shape}")
print(f"å†å²æ•°æ®åˆ—: {list(history_df.columns)}")
```

**å†å²æ•°æ®æ–°å¢å­—æ®µï¼š**

```python
# æ–°å¢å­—æ®µè¯´æ˜
{
    "r2": 0.6832,             # å›å½’æ‹Ÿåˆä¼˜åº¦ RÂ²
    "break_reason": "invalid_width",  # é€šé“å¤±æ•ˆåŸå›  (insufficient_data/no_valid_anchor/invalid_regression/invalid_width)
    "width_pct": 0.1229,      # é€šé“å®½åº¦ç™¾åˆ†æ¯” (ä¸Šæ²¿-ä¸‹æ²¿)/ä¸­è½´ä»·
    "slope_deg": 1.4052,      # æ–œç‡è§’åº¦ï¼ˆåº¦ï¼‰
    "volatility": 0.0320      # æ³¢åŠ¨ç‡ Ïƒ/ä¸­è½´ä»·
}
```

### 2.2 ä¼˜åŒ–è®¡ç®—ï¼ˆæŒ‰æ­¥é•¿ï¼‰

```python
# ä¼˜åŒ–è®¡ç®—ï¼ˆæŒ‰æ­¥é•¿ï¼‰
history_df = analyzer.fit_channel_history_optimized(
    df, 
    min_window_size=60, 
    step_days=5
)

print(f"ä¼˜åŒ–åæ•°æ®å½¢çŠ¶: {history_df.shape}")
```

### 2.3 å¢é‡æ›´æ–°

```python
# å¢é‡æ›´æ–°
new_data = pd.DataFrame({
    'trade_date': pd.date_range('2023-08-01', periods=10, freq='D'),
    'close': [15 + i * 0.01 + np.random.normal(0, 0.1) for i in range(10)]
})

updated_df = analyzer.update_channel_history_incremental(
    history_df, 
    new_data
)

print(f"æ›´æ–°åæ•°æ®å½¢çŠ¶: {updated_df.shape}")
```

---

## âš™ï¸ å‚æ•°é…ç½®

### 3.1 åŸºç¡€å‚æ•°

```python
# åŸºç¡€å‚æ•°é…ç½®
params = {
    "k": 2.0,                 # é€šé“å®½åº¦å€æ•°ï¼Œå½±å“é€šé“çš„å®½åº¦ (Â±kÂ·Ïƒ)
    "L_max": 120,             # çª—å£æœ€é•¿å¤©æ•°ï¼Œè¶…å‡ºåå‘å³æ»‘åŠ¨
    "delta_cut": 5,           # æ»‘åŠ¨æ—¶ä¸€æ¬¡å‰”é™¤æœ€æ—©çš„å¤©æ•°
    "pivot_m": 3              # åˆ¤æ–­pivot lowçš„å®½åº¦å‚æ•° (må·¦må³æ›´é«˜)
}

# ä½¿ç”¨è‡ªå®šä¹‰å‚æ•°
state = analyzer.fit_channel(df, **params)
```

### 3.2 è§¦å‘å‚æ•°

```python
# è§¦å‘å‚æ•°é…ç½®
params = {
    "gain_trigger": 0.30,     # ç´¯è®¡æ¶¨å¹…è§¦å‘é‡é”šçš„é˜ˆå€¼
    "beta_delta": 0.15,       # æ–œç‡å˜åŒ–é˜ˆå€¼ (Â±15%)
    "break_days": 3,          # è¿ç»­næ—¥çªç ´ä¸Šä¸‹æ²¿è§†ä¸ºå¤±æ•ˆ
    "reanchor_fail_max": 2    # è¿ç»­næ¬¡é‡é”šä»çªç ´/è·Œç ´æ—¶è¿›å…¥æç«¯çŠ¶æ€
}
```

### 3.3 è´¨é‡å‚æ•°

```python
# è´¨é‡å‚æ•°é…ç½®
params = {
    "min_data_points": 60,    # æœ€å°æœ‰æ•ˆæ•°æ®ç‚¹è¦æ±‚
    "R2_min": 0.20,           # æœ€å°å›å½’æ‹Ÿåˆä¼˜åº¦ï¼Œä½äºæ­¤è§†ä¸ºæ— æ•ˆé€šé“
    "width_pct_min": 0.04,    # é€šé“å®½åº¦ä¸‹é™ï¼Œå°äºæ­¤è§†ä¸ºè¿‡çª„
    "width_pct_max": 0.12     # é€šé“å®½åº¦ä¸Šé™ï¼Œè¶…è¿‡æ­¤è§†ä¸ºè¿‡å®½
}
```

---

## ğŸ” é«˜çº§åŠŸèƒ½

### 4.1 é€šé“çŠ¶æ€ç›‘æ§

```python
# ç›‘æ§é€šé“çŠ¶æ€å˜åŒ–
def monitor_channel_status(df):
    analyzer = AscendingChannelRegression()
    state = analyzer.fit_channel(df)
    
    status = state.channel_status
    if status == "NORMAL":
        print("âœ… é€šé“çŠ¶æ€æ­£å¸¸")
    elif status == "BREAKOUT":
        print("ğŸš€ ä¸Šæ²¿çªç ´")
    elif status == "BREAKDOWN":
        print("ğŸ“‰ è·Œç ´/å¤±æ•ˆ")
    
    return state

# ä½¿ç”¨ç¤ºä¾‹
state = monitor_channel_status(df)
```

### 4.2 é€šé“è´¨é‡è¯„ä¼°

```python
def evaluate_channel_quality(channel_info):
    """è¯„ä¼°é€šé“è´¨é‡"""
    
    # æ‹Ÿåˆè´¨é‡è¯„ä¼°
    r2 = channel_info.get('r2', 0)
    if r2 > 0.7:
        quality = "ä¼˜ç§€"
    elif r2 > 0.5:
        quality = "è‰¯å¥½"
    else:
        quality = "ä¸€èˆ¬"
    
    # é€šé“å®½åº¦è¯„ä¼°
    width_pct = channel_info.get('width_pct', 0)
    if width_pct < 0.05:
        width_quality = "è¿‡çª„"
    elif width_pct > 0.15:
        width_quality = "è¿‡å®½"
    else:
        width_quality = "é€‚ä¸­"
    
    # è¶‹åŠ¿å¼ºåº¦è¯„ä¼°
    slope_deg = channel_info.get('slope_deg', 0)
    if slope_deg > 5:
        trend_strength = "å¼º"
    elif slope_deg > 1:
        trend_strength = "ä¸­"
    else:
        trend_strength = "å¼±"
    
    return {
        "æ‹Ÿåˆè´¨é‡": f"{quality} ({r2:.3f})",
        "é€šé“å®½åº¦": f"{width_quality} ({width_pct:.2%})",
        "è¶‹åŠ¿å¼ºåº¦": f"{trend_strength} ({slope_deg:.2f}Â°)"
    }

# ä½¿ç”¨ç¤ºä¾‹
quality_report = evaluate_channel_quality(channel_info)
for metric, value in quality_report.items():
    print(f"{metric}: {value}")
```

### 4.3 é¢„æµ‹åŠŸèƒ½

```python
def predict_channel_levels(channel_info, days_ahead=5):
    """é¢„æµ‹æœªæ¥å‡ å¤©çš„é€šé“æ°´å¹³"""
    
    beta = channel_info.get('beta', 0)
    mid_today = channel_info.get('mid_today', 0)
    upper_today = channel_info.get('upper_today', 0)
    lower_today = channel_info.get('lower_today', 0)
    
    predictions = []
    for day in range(1, days_ahead + 1):
        mid_pred = mid_today + beta * day
        upper_pred = upper_today + beta * day
        lower_pred = lower_today + beta * day
        
        predictions.append({
            "day": day,
            "mid": mid_pred,
            "upper": upper_pred,
            "lower": lower_pred
        })
    
    return predictions

# ä½¿ç”¨ç¤ºä¾‹
predictions = predict_channel_levels(channel_info, days_ahead=5)
for pred in predictions:
    print(f"ç¬¬{pred['day']}å¤©: ä¸­è½´={pred['mid']:.2f}, ä¸Šæ²¿={pred['upper']:.2f}, ä¸‹æ²¿={pred['lower']:.2f}")
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### 5.1 æ‰¹é‡å¤„ç†

```python
def batch_process_stocks(stock_codes, start_date, end_date):
    """æ‰¹é‡å¤„ç†å¤šåªè‚¡ç¥¨çš„ä¸Šå‡é€šé“åˆ†æ"""
    
    analyzer = AscendingChannelRegression()
    results = {}
    
    for code in stock_codes:
        try:
            # è·å–è‚¡ç¥¨æ•°æ®
            df = get_stock_data(code, start_date, end_date)
            
            # è®¡ç®—ä¸Šå‡é€šé“
            state = analyzer.fit_channel(df)
            results[code] = state.to_dict()
            
        except Exception as e:
            print(f"å¤„ç†è‚¡ç¥¨ {code} æ—¶å‡ºé”™: {e}")
            results[code] = None
    
    return results

# ä½¿ç”¨ç¤ºä¾‹
stock_codes = ["000001", "000002", "600000"]
results = batch_process_stocks(stock_codes, "2024-01-01", "2024-12-31")
```

### 5.2 ç¼“å­˜ä¼˜åŒ–

```python
from functools import lru_cache

@lru_cache(maxsize=100)
def cached_channel_analysis(stock_code, start_date, end_date):
    """ç¼“å­˜ä¸Šå‡é€šé“åˆ†æç»“æœ"""
    
    analyzer = AscendingChannelRegression()
    df = get_stock_data(stock_code, start_date, end_date)
    state = analyzer.fit_channel(df)
    
    return state.to_dict()

# ä½¿ç”¨ç¤ºä¾‹
result1 = cached_channel_analysis("000001", "2024-01-01", "2024-12-31")
result2 = cached_channel_analysis("000001", "2024-01-01", "2024-12-31")  # ä½¿ç”¨ç¼“å­˜
```

### 5.3 å¹¶è¡Œå¤„ç†

```python
import concurrent.futures
from multiprocessing import Pool

def parallel_channel_analysis(stock_codes, start_date, end_date):
    """å¹¶è¡Œå¤„ç†ä¸Šå‡é€šé“åˆ†æ"""
    
    def process_single_stock(code):
        try:
            analyzer = AscendingChannelRegression()
            df = get_stock_data(code, start_date, end_date)
            state = analyzer.fit_channel(df)
            return code, state.to_dict()
        except Exception as e:
            return code, None
    
    # ä½¿ç”¨çº¿ç¨‹æ± 
    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(process_single_stock, code) for code in stock_codes]
        results = {}
        
        for future in concurrent.futures.as_completed(futures):
            code, result = future.result()
            results[code] = result
    
    return results

# ä½¿ç”¨ç¤ºä¾‹
stock_codes = ["000001", "000002", "600000", "600036"]
results = parallel_channel_analysis(stock_codes, "2024-01-01", "2024-12-31")
```

---

## ğŸ› æ•…éšœæ’é™¤

### 6.1 å¸¸è§é”™è¯¯

```python
# 1. æ•°æ®ä¸è¶³é”™è¯¯
try:
    state = analyzer.fit_channel(df)
except ValueError as e:
    if "insufficient_data" in str(e):
        print("æ•°æ®é‡ä¸è¶³ï¼Œéœ€è¦è‡³å°‘60ä¸ªäº¤æ˜“æ—¥çš„æ•°æ®")
    elif "no_valid_anchor" in str(e):
        print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„é”šç‚¹")
    elif "invalid_regression" in str(e):
        print("å›å½’åˆ†æå¤±è´¥ï¼Œæ‹Ÿåˆè´¨é‡è¿‡ä½")

# 2. å‚æ•°é”™è¯¯
try:
    state = analyzer.fit_channel(df, k=-1)  # æ— æ•ˆå‚æ•°
except ValueError as e:
    print(f"å‚æ•°é”™è¯¯: {e}")

# 3. æ•°æ®æ ¼å¼é”™è¯¯
try:
    state = analyzer.fit_channel(df)
except KeyError as e:
    print(f"æ•°æ®æ ¼å¼é”™è¯¯ï¼Œç¼ºå°‘å¿…éœ€åˆ—: {e}")
```

### 6.2 æ•°æ®éªŒè¯

```python
def validate_data_for_channel_analysis(df):
    """éªŒè¯æ•°æ®æ˜¯å¦é€‚åˆä¸Šå‡é€šé“åˆ†æ"""
    
    # æ£€æŸ¥å¿…éœ€åˆ—
    required_columns = ['trade_date', 'close']
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        return False, f"ç¼ºå°‘å¿…éœ€åˆ—: {missing_columns}"
    
    # æ£€æŸ¥æ•°æ®é‡
    if len(df) < 60:
        return False, f"æ•°æ®é‡ä¸è¶³ï¼Œå½“å‰{len(df)}æ¡ï¼Œéœ€è¦è‡³å°‘60æ¡"
    
    # æ£€æŸ¥æ•°æ®ç±»å‹
    if not pd.api.types.is_datetime64_any_dtype(df['trade_date']):
        return False, "trade_dateåˆ—å¿…é¡»æ˜¯æ—¥æœŸç±»å‹"
    
    # æ£€æŸ¥æ•°å€¼åˆ—
    if not pd.api.types.is_numeric_dtype(df['close']):
        return False, "closeåˆ—å¿…é¡»æ˜¯æ•°å€¼ç±»å‹"
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç©ºå€¼
    if df['close'].isna().any():
        return False, "closeåˆ—åŒ…å«ç©ºå€¼"
    
    return True, "æ•°æ®éªŒè¯é€šè¿‡"

# ä½¿ç”¨ç¤ºä¾‹
is_valid, message = validate_data_for_channel_analysis(df)
if not is_valid:
    print(f"æ•°æ®éªŒè¯å¤±è´¥: {message}")
else:
    print("æ•°æ®éªŒè¯é€šè¿‡ï¼Œå¯ä»¥è¿›è¡Œåˆ†æ")
```

### 6.3 è°ƒè¯•æ¨¡å¼

```python
import logging

# è®¾ç½®è°ƒè¯•æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)
logger = logging.getLogger(__name__)

def debug_channel_analysis(df):
    """è°ƒè¯•æ¨¡å¼ä¸‹çš„ä¸Šå‡é€šé“åˆ†æ"""
    
    logger.debug(f"è¾“å…¥æ•°æ®å½¢çŠ¶: {df.shape}")
    logger.debug(f"æ•°æ®åˆ—: {list(df.columns)}")
    logger.debug(f"æ•°æ®èŒƒå›´: {df['trade_date'].min()} åˆ° {df['trade_date'].max()}")
    
    analyzer = AscendingChannelRegression()
    
    try:
        state = analyzer.fit_channel(df)
        logger.debug(f"åˆ†ææˆåŠŸï¼Œé€šé“çŠ¶æ€: {state.channel_status}")
        return state
    except Exception as e:
        logger.error(f"åˆ†æå¤±è´¥: {e}")
        raise

# ä½¿ç”¨ç¤ºä¾‹
state = debug_channel_analysis(df)
```

---

## ğŸ“š å®Œæ•´ç¤ºä¾‹

### 7.1 å®Œæ•´çš„ä¸Šå‡é€šé“åˆ†ææµç¨‹

```python
import pandas as pd
import numpy as np
from backend.business.factor.core.engine.library.channel_analysis import AscendingChannelRegression
from backend.business.data.data_fetcher import StockDataFetcher

def complete_channel_analysis(stock_code, start_date, end_date):
    """å®Œæ•´çš„ä¸Šå‡é€šé“åˆ†ææµç¨‹"""
    
    # 1. è·å–æ•°æ®
    fetcher = StockDataFetcher()
    df = fetcher.fetch_stock_data(stock_code, start_date, end_date)
    
    # 2. æ•°æ®éªŒè¯
    is_valid, message = validate_data_for_channel_analysis(df)
    if not is_valid:
        print(f"æ•°æ®éªŒè¯å¤±è´¥: {message}")
        return None
    
    # 3. ä¸Šå‡é€šé“åˆ†æ
    analyzer = AscendingChannelRegression()
    state = analyzer.fit_channel(df)
    channel_info = state.to_dict()
    
    # 4. è´¨é‡è¯„ä¼°
    quality_report = evaluate_channel_quality(channel_info)
    
    # 5. é¢„æµ‹
    predictions = predict_channel_levels(channel_info, days_ahead=5)
    
    # 6. ç»“æœæ±‡æ€»
    result = {
        "stock_code": stock_code,
        "analysis_date": end_date,
        "channel_info": channel_info,
        "quality_report": quality_report,
        "predictions": predictions
    }
    
    return result

# ä½¿ç”¨ç¤ºä¾‹
result = complete_channel_analysis("000001", "2024-01-01", "2024-12-31")

if result:
    print(f"è‚¡ç¥¨ä»£ç : {result['stock_code']}")
    print(f"åˆ†ææ—¥æœŸ: {result['analysis_date']}")
    print(f"é€šé“çŠ¶æ€: {result['channel_info']['channel_status']}")
    print(f"æ‹Ÿåˆè´¨é‡: {result['quality_report']['æ‹Ÿåˆè´¨é‡']}")
    print(f"é€šé“å®½åº¦: {result['quality_report']['é€šé“å®½åº¦']}")
    print(f"è¶‹åŠ¿å¼ºåº¦: {result['quality_report']['è¶‹åŠ¿å¼ºåº¦']}")
```

---

**æœ€åæ›´æ–°æ—¶é—´**: 2025å¹´8æœˆ5æ—¥
**æ–‡æ¡£ç‰ˆæœ¬**: v2.0 