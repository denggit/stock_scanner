# Python 市场热点 Agent 项目开发计划

本项目旨在通过 Python 复刻 `go-stock` 的核心理念，并专注于创建一个能够每日自动抓取、分析并总结股票市场热点的智能 Agent。

## **第一阶段：数据基石 - 构建稳定可靠的数据源**

此阶段的核心目标是建立一个强大的数据层，为后续的 AI 分析提供高质量的“燃料”。

### **模块 1：实时行情获取器 (`stock_data_fetcher.py`)**

  * **目标**: 获取股票的实时价格、成交量、涨跌幅等核心交易数据。
  * **实现**:
    1.  **分析数据源**: 参考 `go-stock` 项目中的 `backend/data/stock_data_api.go` 文件，确定其使用的行情接口，主要是新浪财经和腾讯财经。
    2.  **编写请求函数**: 使用 `requests` 库向以下接口发送 HTTP GET 请求：
          * 新浪财经: `http://hq.sinajs.cn/list=[股票代码]`
          * 腾讯财经: `http://qt.gtimg.cn/q=[股票代码]`
    3.  **数据解析**: 编写一个解析函数，用于处理接口返回的特定格式字符串（例如 `var hq_str_sh600519="贵州茅台,..."`）。使用字符串分割和类型转换，将数据解析为结构化的 Python 字典或自定义的 `StockQuote` 数据类。
  * **关键库**: `requests`

### **模块 2：财经资讯爬虫 (`news_crawler.py`)**

  * **目标**: 抓取各大主流财经网站的新闻、快讯和公司公告，这是识别市场热点的关键信息源。
  * **实现**:
    1.  **确定目标网站**: 从 `market_news_api.go` 中找到财联社 (`cls.cn`)、新浪财经等关键信息源。
    2.  **静态内容抓取**: 对新浪财经等传统网站，使用 `requests` 获取 HTML 内容，再用 `BeautifulSoup4` 解析页面，提取新闻的标题、链接、发布时间和正文摘要。
    3.  **动态内容抓取 (进阶)**: 对于财联社这类通过 JavaScript 动态加载内容的网站，需要使用 `selenium` 或 `playwright`。这两个库可以模拟真实浏览器行为，等待数据加载完成后再抓取页面内容。
  * **关键库**: `requests`, `beautifulsoup4`, `selenium` / `playwright`

### **模块 3：基础数据管理器 (`fundamental_data_manager.py`)**

  * **目标**: 获取股票的基本信息（如所属行业、地区）、历史 K 线数据和财务数据。
  * **实现**:
    1.  **首选方案 (Tushare)**:
          * 注册 Tushare Pro 账号以获取 API token。
          * 使用官方的 `tushare` Python 库，调用其丰富的接口来获取股票列表、日线行情、财务报表等高质量数据。这是最便捷且数据最全面的方式。
    2.  **备选方案 (yfinance)**:
          * 如果不想依赖 Tushare，可以使用 `yfinance` 库。它能从雅虎财经免费获取全球股票（包括 A 股）的历史 K 线数据和部分基本信息。
  * **关键库**: `tushare`, `yfinance` (备选)

-----

## **第二阶段：数据仓库 - 结构化存储与管理**

此阶段的目标是为所有抓取到的数据建立一个本地的、结构化的存储系统。

### **模块 4：数据库模型定义 (`database/models.py`)**

  * **目标**: 使用 ORM (对象关系映射) 定义数据表结构，使 Python 代码能以面向对象的方式操作数据库。
  * **实现**:
    1.  **选择 ORM**: `SQLAlchemy` 是 Python 中功能最强大、社区最活跃的 ORM 库。
    2.  **定义模型**: 创建多个 Python 类，每个类对应一张数据表。例如：
          * `StockBasicInfo`: 存储股票代码、名称、行业等基本信息。
          * `DailyQuote`: 存储每日的开盘、收盘、最高、最低价和成交量。
          * `NewsArticle`: 存储新闻的标题、摘要、来源和发布时间。
    3.  **数据库引擎**: 使用 `SQLite`，它是一个轻量级的本地文件数据库，无需额外配置，非常适合本项目。
  * **关键库**: `sqlalchemy`

### **模块 5：数据持久化层 (`database/crud.py`)**

  * **目标**: 编写统一的函数来执行数据的增、删、改、查 (CRUD) 操作，将第一阶段获取的数据存入数据库。
  * **实现**:
      * **创建会话**: 使用 `SQLAlchemy` 的 `Session` 来管理数据库连接和事务。
      * **编写存储函数**: 为每个数据模型编写 `create_`、`get_`、`update_` 函数。例如 `create_news_articles(articles_data)` 函数，用于批量将抓取的新闻存入数据库。
      * **编写查询接口**: 提供上层应用所需的查询功能，如 `get_news_by_date(date)`，方便 Agent 调用。
  * **关键库**: `sqlalchemy`

-----

## **第三阶段：智能核心 - 构建市场热点 Agent**

这是项目的核心创新点，将数据转化为洞察。

### **模块 6：信息处理器 (`agent/preprocessor.py`)**

  * **目标**: 在将数据喂给大语言模型 (LLM) 之前，进行必要的清洗和整合。
  * **实现**:
    1.  **数据聚合**: 编写函数，从数据库中提取指定时间范围（如过去24小时）的所有新闻标题和摘要。
    2.  **文本清洗**: 使用正则表达式或字符串函数，去除无关字符、广告语、HTML 标签等噪音。
    3.  **格式化**: 将所有清洗后的文本整合成一个单一的、结构化的字符串，作为 LLM 的输入上下文。
  * **关键库**: `re` (正则表达式)

### **模块 7：热点分析 Agent (`agent/hotspot_agent.py`)**

  * **目标**: 设计并实现一个能够调用 LLM 并从中提炼出市场热点的智能代理。
  * **实现**:
    1.  **集成 LLM**:
          * **框架**: 强烈推荐使用 `LangChain` 或 `LlamaIndex`。这些框架极大地简化了与 LLM 的交互、Prompt 管理和工具调用。
          * **连接**: 配置连接到你选择的 LLM。可以是 OpenAI 的 API，也可以是通过 Ollama 运行的本地模型。
    2.  **设计核心 Prompt**: 这是 Agent 的“灵魂”，一个好的 Prompt 是成功的关键。你的 Prompt 应该清晰地指示 LLM 完成以下任务：
        ```
        你是一位顶级的金融市场分析师。请仔细阅读以下今天收集到的所有财经新闻资讯：
        {news_context}

        请基于以上信息，完成以下任务：
        1. 总结出今天市场最核心的 3 到 5 个热点板块或主题。
        2. 对每个热点，列出至少 3 个直接相关的股票名称和代码。
        3. 简要分析每个热点出现的原因（例如：政策发布、技术突破、行业事件等）。
        4. 综合所有信息，判断今天市场的整体情绪是“乐观”、“悲观”还是“中性”，并给出理由。

        请以 Markdown 格式返回你的分析报告。
        ```
    3.  **调用与解析**: 使用 `LangChain` 执行 Prompt，并获取 LLM 返回的 Markdown 格式的分析报告。
  * **关键库**: `langchain`, `langchain-openai` / `langchain-community` (用于Ollama)

-----

## **第四阶段：调度与呈现 - 自动化与用户交互**

此阶段的目标是让整个系统自动化运行，并以友好的方式展示结果。

### **模块 8：任务调度器 (`scheduler.py`)**

  * **目标**: 创建一个定时任务，让数据抓取和分析流程每天自动在后台执行。
  * **实现**:
      * 使用 `apscheduler` 库，配置一个定时作业 (cron job)。
      * **调度逻辑**: 设置在每个交易日的收盘后（例如下午 4:00）触发。
      * **任务编排**: 调度器将按顺序调用前序模块的函数：数据抓取 -\> 数据存储 -\> 信息预处理 -\> Agent 分析 -\> 结果存储。
  * **关键库**: `apscheduler`

### **模块 9：结果展示 (`main.py` 或 `app.py`)**

  * **目标**: 为用户提供一个查看每日热点分析报告的界面。
  * **实现**:
    1.  **命令行界面 (CLI)**: 最简单的方式。通过 `argparse` 库创建一个命令行工具，用户可以通过运行 `python main.py show-hotspots` 来在终端查看最新的分析报告。
    2.  **Web 界面 (推荐)**: 使用 `FastAPI` 或 `Flask` 快速搭建一个轻量级的 Web 服务器。创建一个简单的 HTML 页面，用于展示 Agent 生成的 Markdown 报告。这是最灵活且用户体验最好的方式。
  * **关键库**: `argparse` (CLI), `fastapi`/`flask` (Web)